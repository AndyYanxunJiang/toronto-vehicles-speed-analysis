---
title: "Analyzing Toronto Traffic Speeds: Insights into Patterns and Predictive Modeling"
subtitle: "Bayesian Linear Regression Reveals Key Determinants of Mean Speed and Post-Pandemic Trends"
author: 
  - Andy Jiang
thanks: "Code and data are available at: https://github.com/AndyYanxunJiang/toronto-vehicles-speed-analysis."
date: today
date-format: long
abstract: "This paper investigates traffic speed data from Toronto collected between 2017 and 2024, focusing on trends in speed percentiles and their relationship to traffic volume. Using a Bayesian linear regression model, we predict mean vehicle speeds based on key predictors such as 5th, 50th, and 95th percentile speeds and total traffic volume. Results highlight significant changes in traffic patterns post-2020, with increased extreme speeds linked to higher traffic volumes. This study provides insights into urban mobility dynamics, offering a basis for traffic management strategies and policy-making."
format: pdf
number-sections: true
bibliography: references.bib
toc: true
---

```{r}
#| include: false
#| warning: false
#| message: false

# Load necessary libraries
library(tidyverse)
library(ggplot2)
library(here)
library(kableExtra)
library(rstanarm)
library(modelsummary)
library(dplyr)
library(lubridate)

# Load the cleaned speed data
data <- read_csv(here::here("data/02-analysis_data/analysis_speed_data.csv"))

# Ensure the data is ready for analysis
data <- data %>%
  mutate(
    month = as.Date(month)  # Ensure the 'month' column is in Date format
  )

# Prepare the data used in the model
analysis_data <- data

analysis_data <- analysis_data %>%
  mutate(
    spd_mean = rowMeans(select(., starts_with("pct_")), na.rm = TRUE)
  )

filtered_data <- analysis_data %>%
  filter(
    !is.na(spd_mean),  # Ensure the response variable has no missing values
    !is.na(volume),    # Ensure predictors have no missing values
    !is.na(pct_05),    # Include pct_05
    !is.na(pct_50),
    !is.na(pct_95)
  )

# Read model
mean_speed_model <- readRDS(file = here::here("models/speed_model.rds"))
```


# Introduction
Traffic speed analysis is a critical tool for understanding urban mobility, road safety, and congestion. In metropolitan areas like Toronto, shifting traffic patterns reflect changes in urban infrastructure, population growth, and behavioral adaptations to external events, such as the COVID-19 pandemic. The advent of technologies like radar-equipped speed signs has enabled the collection of detailed traffic data, providing new opportunities to analyze and predict traffic behavior at a granular level.

This paper focuses on traffic speed data collected in Toronto's designated Safety Zones between 2017 and 2024. The dataset comprises monthly summaries of speed percentiles, vehicle counts across specific speed ranges, and total traffic volumes. Notably, the study explores trends in extreme speeds (vehicles exceeding 100 km/h) and evaluates how they have evolved before and after 2020, a period marked by rapid population growth and post-pandemic recovery. These analyses aim to address a key gap: understanding how percentile-based speed measures and traffic volume influence overall mean speeds.

To investigate these relationships, we employ a Bayesian linear regression model to predict mean vehicle speed (`spd_mean`) based on predictors including 5th, 50th, and 95th percentile speeds and traffic volume. Bayesian modeling allows for the incorporation of uncertainty and prior information, making it well-suited for analyzing urban traffic data.

Our findings reveal significant changes in traffic behavior post-2020, including higher extreme speed occurrences at increased traffic volumes, reflecting broader shifts in urban mobility. This study highlights the importance of percentile-based metrics in predicting mean speeds and contributes to ongoing efforts to enhance traffic safety and efficiency. The paper is structured as follows: the data section provides an overview of the dataset and key variables, the model section outlines the Bayesian regression framework, results are discussed in detail, and the discussion section reflects on the implications and limitations of the findings.

The remainder of this paper is structured as follows. @sec-data discusses the raw data, cleaning process, and key variables of interest, offering visual and tabular representations of the dataset. @sec-model introduces and justifies the Bayesian linear regression model used to analyze the relationship between traffic volume, speed percentiles, and mean vehicle speed. @sec-results presents the findings of the model, highlighting significant trends and correlations within the data. Finally, @sec-discussion explores the broader implications of these results, offering insights into traffic behavior and potential avenues for future research. Additional information regarding data observation methodology is provided in [Appendix -@sec-dataobservation], and further model diagnostics are detailed in [Appendix -@sec-model-details].


# Data {#sec-data}

The data used in this paper came from the Open Data Toronto portal through the library opendatatoronto [@citeODT], specifically the Safety Zone Watch Your Speed Program – Monthly Summary [@SpeedDataCite]. All data analysis was conducted using R [@citeR] with the support of the following packages: tidyverse [@tidyverse], here [@here], ggplot2 [@ggplot2], rstanarm [@rstanarm], kableExtra [@kableExtra], modelsummary [@modelsummary], dplyr [@dplyr], and lubridate [@lubridate]. These packages provided a robust framework for data manipulation, visualization, Bayesian modeling, and reporting, facilitating reproducible and efficient analysis.

## Overview
This paper analyzes traffic speed data collected in Toronto over the period 2017–2024. The dataset contains detailed information on percentile speeds, total traffic volume, and counts of vehicles traveling within specific speed ranges. These data provide an opportunity to study the evolution of traffic patterns in Toronto, especially in the context of changing demographics, urbanization, and post-pandemic recovery.

The dataset aggregates metrics monthly, offering insights into how traffic behavior has changed over time. This analysis is particularly focused on extreme speeds (vehicles exceeding 100 km/h) and their relationship with total traffic volume, as well as trends in key speed percentiles.

## Measurement
	
The dataset analyzed in this paper originates from the Safety Zone Watch Your Speed Program (WYSP), a City of Toronto initiative designed to monitor and influence driver behavior in designated Safety Zones. Data are collected using radar-equipped speed display signs installed on hydro poles or streetlights, which measure the speeds of oncoming vehicles with an accuracy of ±1 km/h and display the speeds on LED screens to encourage compliance with speed limits. These measurements are aggregated into monthly summaries, including key metrics such as percentile speeds (e.g., 5th, 50th, 95th percentiles), vehicle counts within specific speed ranges, and total observed traffic volume. The dataset is curated and published by Open Data Toronto, which ensures its metadata quality, completeness, and accessibility.

However, the dataset has certain limitations. The number of vehicles recorded by the speed signs is not equivalent to true traffic volume, as it may exclude vehicles that pass too quickly or fall outside the radar’s range. Additionally, the presence of the signs might influence driver behavior, leading to changes in speed as drivers approach them. Furthermore, the data is limited to Safety Zones where the speed signs have been installed, restricting its spatial coverage. Despite these limitations, the dataset is well-documented, complete, and up-to-date, providing valuable insights into traffic speed patterns across Toronto.


## Speed Dataset Preview
The traffic speed dataset contains information collected from multiple locations and months, detailing percentile speeds, total traffic volume, and counts of vehicles traveling within specific speed ranges. The dataset aggregates these metrics monthly, offering insights into traffic behavior and variations over time.

This dataset includes:
- Percentile speeds (5th, 10th, ... 95th) representing speed thresholds exceeded by corresponding proportions of vehicles.
- Traffic volume as the total number of vehicles observed monthly.
- Speed bins (e.g., 0-4 km/h, 5-9 km/h) for detailed breakdowns of vehicle counts across speed ranges.
- @tbl-speed-preview showcases a simplified preview of the dataset with selected columns to highlight key features.

```{r}
#| label: tbl-speed-preview
#| tbl-cap: Preview of analysis traffic speed dataset.
#| echo: false
#| tbl-pos: H

data |> 
  select(month, pct_05, pct_95, spd_100_and_above, volume) |> 
  head(10) |> 
  kable(
    col.names = c("Month", "5th Percentile", "95th Percentile", "Vehicles (>100 km/h)", "Total Volume"),
    booktabs = TRUE
  )


```

## Random Sample from the Dataset
@tbl-random-sample provides a random sample of 10 observations, offering an unbiased snapshot of key metrics such as speed percentiles, total traffic volume, and counts of vehicles exceeding 100 km/h. This selection illustrates the dataset's diversity without emphasizing specific patterns.

```{r}
#| label: tbl-random-sample
#| tbl-cap: Random sample of traffic speed dataset.
#| echo: false
#| tbl-pos: H

set.seed(304)  # For reproducibility
data |> 
  sample_n(10) |> 
  select(month, pct_05, pct_95, spd_100_and_above, volume) |> 
  kable(
    col.names = c("Month", "5th Percentile", "95th Percentile", "Vehicles (>100 km/h)", "Total Volume"),
    booktabs = TRUE
  )

```

## Extreme Speeds Dataset
Vehicles traveling at extreme speeds (over 100 km/h) represent a critical factor in understanding traffic safety and violations. @tbl-extreme-speeds highlights the top 5 months with the highest counts of vehicles exceeding 100 km/h. This provides insights into when extreme speeds are most prevalent.

```{r}
#| label: tbl-extreme-speeds
#| tbl-cap: Top 5 months with the highest counts of vehicles exceeding 100 km/h.
#| echo: false
#| tbl-pos: H

data |> 
  arrange(desc(spd_100_and_above)) |> 
  head(5) |> 
  select(month, volume, spd_100_and_above, pct_95) |> 
  kable(
    col.names = c("Month", "Total Volume", "Vehicles (>100 km/h)", "95th Percentile Speed"),
    booktabs = TRUE
  )

```

## Proportion of Vehicles at Moderate Speeds
Another key insight from this dataset is the proportion of vehicles traveling within a moderate speed range (50–70 km/h). This measure helps understand how typical driving speeds align with safe and efficient traffic flow.

@tbl-speed-proportion highlights monthly proportions of vehicles in this speed range.

```{r}
#| label: tbl-speed-proportion
#| tbl-cap: Monthly proportions of vehicles traveling at moderate speeds (50–70 km/h).
#| echo: false
#| tbl-pos: H

moderate_speed <- data %>%
  mutate(month = lubridate::month(month, label = TRUE, abbr = TRUE)) %>%
  group_by(month) %>%
  summarise(
    moderate_speed_count = sum(spd_50 + spd_55 + spd_60 + spd_65 + spd_70, na.rm = TRUE),
    total_volume = sum(volume, na.rm = TRUE),
    proportion_moderate = round((moderate_speed_count / total_volume) * 100, 2)
  ) 

moderate_speed |> 
  kable(
    col.names = c("Month", "Moderate Speed Vehicles", "Total Volume", "Proportion (%)"), 
    booktabs = TRUE
  )

```


## Extreme Speeds and Traffic Volume

@fig-extreme-speeds-vs-volume illustrates the relationship between extreme speeds (vehicles traveling over 100 km/h) and total traffic volume, categorized by pre-2020 and post-2020 periods. The post-2020 data points show a significant increase in both traffic volume and extreme speed counts, with some months recording over 2,000 vehicles exceeding 100 km/h. This increase may reflect changes in traffic behavior following the COVID-19 pandemic and a rapid population influx into Toronto through immigration. In contrast, pre-2020 data points display lower traffic volumes and fewer extreme speed counts, rarely exceeding 2,000. The fitted lines for each period highlight this divergence, with a steeper slope for post-2020 data, suggesting that higher traffic volumes post-pandemic are associated with a broader range of extreme speed occurrences.

```{r}
#| label: fig-extreme-speeds-vs-volume
#| fig-cap: Relationship between extreme speeds (over 100 km/h) and total traffic volume, categorized by pre-2020 and post-2020 time periods.
#| echo: false
#| warning: false
#| message: false

# Process the data for analysis
extreme_vs_volume <- data %>%
  group_by(month) %>%
  summarise(
    extreme_count = sum(spd_100_and_above, na.rm = TRUE),
    total_volume = sum(volume, na.rm = TRUE)
  ) %>%
  mutate(period = ifelse(month < as.Date("2020-01-01"), "Pre-2020", "Post-2020"))

# Plot Extreme Speeds vs Total Traffic Volume by Time Period
ggplot(extreme_vs_volume, aes(x = total_volume, y = extreme_count, color = period)) +
  geom_point(size = 2, alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    x = "Total Traffic Volume",
    y = "Extreme Speeds (Over 100 km/h)",
    color = "Time Period"
  ) +
  theme_minimal()


```

## Trends in Key Percentiles

@fig-key-percentiles examines trends in key speed percentiles (5th, 50th, and 95th percentiles) from 2017 to 2024, along with the average speed spread (the difference between the 95th and 5th percentiles). The 95th percentile speed demonstrates a clear decline, falling below 50 km/h over the years. Similarly, the 50th percentile speed dropped significantly between 2017 and 2018, stabilizing at around 30 km/h with minor fluctuations. The 5th percentile speed remained steady until mid-2022, when it experienced a noticeable decline to 5 km/h, down from its previous 10 km/h range. Despite these shifts, the speed spread remains relatively consistent, ranging between 35 and 40 km/h, indicating that the overall variability in speeds has not significantly changed. These trends may reflect broader changes in traffic regulations, driver behavior, or urban infrastructure developments in Toronto.

```{r}
#| label: fig-key-percentiles
#| fig-cap: Trends in key speed percentiles (5th, 50th, and 95th) and the spread between the 95th and 5th percentiles over time.
#| echo: false
#| warning: false
#| message: false
# Summarize Key Percentiles and Calculate Speed Spread
key_percentiles <- data %>%
  group_by(month) %>%
  summarise(
    pct_05 = mean(pct_05, na.rm = TRUE),
    pct_50 = mean(pct_50, na.rm = TRUE),
    pct_95 = mean(pct_95, na.rm = TRUE)
  ) %>%
  mutate(speed_spread = pct_95 - pct_05)  # Calculate spread

# Plot Key Percentiles and Spread
ggplot(key_percentiles, aes(x = month)) +
  geom_line(aes(y = pct_05, color = "5th Percentile")) +
  geom_line(aes(y = pct_50, color = "Median (50th Percentile)")) +
  geom_line(aes(y = pct_95, color = "95th Percentile")) +
  geom_line(aes(y = speed_spread, color = "Speed Spread"), linetype = "dashed") +
  labs(
    x = "Time",
    y = "Speed (km/h)",
    color = "Legend"
  ) +
  theme_minimal()

```


## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.




# Model {#sec-model}

The purpose of this paper is to analyze the relationship between traffic volume, speed percentiles, and the mean speed of vehicles observed in Toronto. By utilizing a Bayesian linear regression model, we aim to investigate how various speed percentiles and total traffic volume predict the average vehicle speed (`spd_mean`). This model enables us to quantify the contributions of different speed measures and traffic density to overall traffic dynamics.

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

The Bayesian multiple linear regression model used in this paper predicts the mean speed (`spd_mean`) as a function of total traffic volume (`volume`) and speed percentiles (`pct_05`, `pct_50`, and `pct_95`). The model is defined as follows:

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \beta_0 + \beta_1 \cdot \text{volume}_{i} + \beta_2 \cdot \text{pct\_05}_{i} + \beta_3 \cdot \text{pct\_50}_{i} + \beta_4 \cdot \text{pct\_95}_{i} \\
\beta_0 &\sim \mbox{Normal}(0, 2.5) \\
\beta_1 &\sim \mbox{Normal}(0, 2.5) \\
\beta_2 &\sim \mbox{Normal}(0, 2.5) \\
\beta_3 &\sim \mbox{Normal}(0, 2.5) \\
\beta_4 &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

In the above model:

- $\mu_i$ is the predicted mean speed (`spd_mean`) for the $i$-th observation given the total traffic volume and speed percentiles.
- $\beta_0$ is the coefficient for the intercept.
- $\beta_1$ is the coefficient for the predicted change in the mean speed given a one-unit increase in traffic volume (`volume`).
- $\beta_2$ is the coefficient for the predicted change in the mean speed given a one-unit increase in the 5th percentile speed (`pct_05`).
- $\beta_3$ is the coefficient for the predicted change in the mean speed given a one-unit increase in the 50th percentile speed (`pct_50`).
- $\beta_4$ is the coefficient for the predicted change in the mean speed given a one-unit increase in the 95th percentile speed (`pct_95`).
- $\sigma$ is the standard deviation of the residuals, representing unexplained variability in the mean speed.


We run the model in R [@citeR] using the `rstanarm` package of [@rstanarm]. We use the default priors from `rstanarm`.


### Model justification

The above model was chosen to investigate the relationship between the average speed (`spd_mean`) of vehicles and key predictors, including total traffic volume (`volume`) and speed percentiles (`pct_05`, `pct_50`, and `pct_95`). These variables were selected because they provide a comprehensive view of traffic patterns and vehicle behavior across different speed thresholds.

The percentiles represent critical thresholds of speed distribution, with the 5th percentile (`pct_05`) capturing the slowest vehicles, the 50th percentile (`pct_50`) representing the median speed, and the 95th percentile (`pct_95`) reflecting the fastest vehicles. These thresholds are expected to influence the average speed significantly. Similarly, total traffic volume (`volume`) accounts for overall road congestion and is anticipated to impact the mean speed inversely, as higher volumes may reduce average speeds due to congestion.

We employ a Bayesian linear regression model implemented using the `rstanarm` package [@rstanarm]. This approach provides a probabilistic framework for parameter estimation and allows the incorporation of prior information. Default priors were used for the regression coefficients (`Normal(0, 2.5)`) and residual standard deviation (`Exponential(1)`), as they are appropriate for general regression problems without overly constraining the estimates.

The linearity assumption is reasonable given the nature of traffic data, where incremental changes in predictors like percentiles and volume are expected to have proportional effects on the mean speed. However, this model does not capture potential nonlinearities or interactions, which could be explored in future work if evidence suggests their relevance.

We hypothesize that:

- Higher 5th, 50th, and 95th percentile speeds will correspond to higher average speeds.
- Higher traffic volumes will be associated with lower average speeds due to congestion effects.
This model's simplicity balances interpretability with analytical rigor, making it a suitable choice for understanding traffic patterns and their determinants.


# Results {#sec-results}

## Model Coefficients
The Bayesian linear regression model results, summarized in @tbl-modelsummary, provide insight into the relationship between mean traffic speed (`spd_mean`) and key predictors such as speed percentiles and traffic volume.

```{r}
#| label: tbl-modelsummary
#| tbl-cap: Model summary of the predicted impact of traffic volume and speed percentiles on mean speed.
#| eval: false
#| echo: false
#| warning: false
#| message: false
#| tbl-pos: H

modelsummary(mean_speed_model)
```

The coefficient estimates reveal the following relationships:

- Intercept (`-0.881`): This represents the baseline adjustment to the mean speed when all predictors are at their reference levels.
- Traffic Volume (`0.000`): The coefficient indicates no measurable impact of total traffic volume on mean speed, which is unexpected given traditional congestion dynamics.
- 5th Percentile Speed (`0.206`): Lower speeds positively influence the mean, showing that slower-moving vehicles contribute moderately to the overall average.
- 50th Percentile Speed (`0.652`): Median speeds have the largest positive effect on mean speed, emphasizing their central role in shaping the distribution of traffic speeds.
- 95th Percentile Speed (`0.184`): Higher speeds have a smaller but still positive influence on mean speed, reflecting their contribution to the upper end of the distribution.

The model's performance metrics underscore its robustness:

- R² and Adjusted R² (`0.992`): The model explains 99.2% of the variance in mean speed, indicating excellent fit.
- Log-Likelihood (`-41414.100`): Represents the model's likelihood given the data.
- WAIC and LOOIC (`82872.9`): These information criteria indicate model performance, balancing goodness-of-fit and model complexity.
- RMSE (`0.88`): A low root mean square error confirms the model's predictive accuracy.

These results highlight the dominant role of speed percentiles in determining mean speed while raising questions about the negligible impact of traffic volume. Further exploration into potential interactions or omitted variables could clarify this finding.


## Actual vs. Predicted Mean Speeds
To evaluate the predictive performance of our Bayesian linear regression model, we compare the predicted mean speeds, derived from the model, with the actual observed mean speeds in the dataset. The comparison is visualized in @fig-actualvspredicted.

```{r}
#| label: fig-actualvspredicted
#| fig-cap: Comparison of actual and predicted mean speeds.
#| echo: false
#| warning: false
#| message: false
#| fig-pos: H

filtered_data <- filtered_data %>%
  mutate(
    predicted = predict(mean_speed_model, newdata = filtered_data)
  )

ggplot(filtered_data, aes(x = predicted, y = spd_mean)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(
    x = "Predicted Mean Speeds",
    y = "Actual Mean Speeds"
  ) +
  theme_minimal()

```

In @fig-actualvspredicted, each point represents an observation where the x-axis denotes the predicted mean speed, and the y-axis shows the actual mean speed. The red dashed line represents the ideal case where predictions perfectly match the actual values (i.e., a 45-degree reference line). Observations closely aligning with the dashed line indicate a strong agreement between predicted and actual values.

The model demonstrates strong predictive accuracy, as the majority of points cluster tightly along the dashed line with minimal deviation. This close alignment suggests that the model captures the relationship between the predictors (`pct_05`, `pct_50`, `pct_95`, and `volume`) and the response variable (`spd_mean`) effectively, with minimal systematic bias.

Notably, there are only a few points where slight deviations from the line are visible, mostly at higher mean speed values. This could be attributed to minor outliers or unique conditions not fully explained by the model's predictors. Overall, the results confirm the reliability of the Bayesian model in predicting mean traffic speeds, especially for the typical speed ranges observed in the dataset.

We explore the broader implications of these results, including potential improvements or limitations in the model, in @sec-discussion.


# Discussion {#sec-discussion}

## Post-pandemic trends and implications for traffic management {#sec-postpandemic}

The analysis in @fig-extreme-speeds-vs-volume illustrates the significant divergence in traffic patterns between the pre- and post-2020 periods. Post-pandemic traffic volumes are notably higher and are accompanied by an increase in extreme speeds (vehicles traveling over 100 km/h). This trend may reflect the rapid population growth in Toronto, driven by immigration, alongside shifts in urban mobility post-COVID-19.

The steeper slope for post-2020 data in @fig-extreme-speeds-vs-volume suggests that extreme speed counts have become more sensitive to increases in traffic volume. One potential explanation for this is the stress placed on infrastructure as more drivers navigate an increasingly dense urban network. These findings highlight the importance of re-evaluating existing traffic management strategies and prioritizing policies that address the dangers posed by extreme speeds in high-traffic environments.

Targeted interventions, such as extending safety zones, introducing stricter enforcement of speed limits, or implementing dynamic speed regulation systems, could help mitigate the risks associated with this upward trend in extreme speeds. Additionally, these findings underscore the importance of accounting for macro-level disruptions, like the pandemic, in transportation policy design to better anticipate and address evolving urban mobility challenges.

## Variability in speed percentiles and safety implications {#sec-variability}

The trends in speed percentiles visualized in @fig-key-percentiles reveal nuanced changes in traffic behavior over time. While the 95th percentile speed has shown a steady decline to below 50 km/h, suggesting progress in limiting higher speeds, the sharp drop in the 5th percentile speed since mid-2022 warrants attention. A decline from approximately 10 km/h to 5 km/h may indicate increased congestion, construction zones, or other road conditions causing slower-moving traffic. This could create a wider speed differential among vehicles, potentially leading to more frequent and severe accidents.

The stability of the 50th percentile speed at approximately 30 km/h reflects consistency in typical driving conditions, while the steady spread between the 5th and 95th percentiles (35–40 km/h) points to minimal change in speed variability. However, the importance of addressing the outliers at the extremes cannot be overstated, as they have disproportionate safety implications. This analysis supports the need for targeted measures to minimize variability in speeds, including enhanced road design and enforcement strategies to reduce abrupt accelerations or decelerations.

## Limitations in modeling and data interpretation {#sec-limitations}

While the Bayesian linear regression model employed in this paper provides meaningful insights into the relationship between key predictors and mean vehicle speed, several limitations warrant discussion. As highlighted in @sec-model, the model does not account for potential interactions among predictors, such as the interplay between traffic volume and percentile speeds. For instance, higher traffic volumes may disproportionately affect the 5th percentile speed compared to the 95th percentile, but this relationship remains unexplored due to the model’s linear structure.

Additionally, as noted in @sec-data, the dataset’s reliance on radar-equipped safety zone signs introduces biases related to location and driver behavior. Vehicles may reduce speed upon approaching these signs, potentially underestimating typical speed distributions for the broader road network. Moreover, the dataset aggregates observations monthly, which may obscure short-term fluctuations in traffic patterns.

Future modeling efforts could incorporate interaction terms and hierarchical structures to better capture the complexity of traffic dynamics. Similarly, integrating data from diverse monitoring systems (e.g., highway cameras or GPS datasets) could provide a more comprehensive view of Toronto’s traffic behavior across different contexts.

## Policy recommendations and future directions {#sec-policy}

The findings in this paper provide a valuable foundation for improving traffic safety and efficiency in Toronto. Several actionable recommendations emerge:

- Enhance enforcement and safety measures for extreme speeds: As post-2020 trends demonstrate a growing prevalence of extreme speeds, prioritizing enforcement in high-traffic areas could reduce associated risks. The use of automated speed cameras, stricter penalties for excessive speeding, and expanded safety zone coverage are potential solutions.

- Address speed variability through road design: Consistent median speeds and limited speed spreads are desirable for traffic flow and safety. Urban planning efforts should focus on designing roads that naturally discourage extreme speeds while avoiding conditions that create bottlenecks for slower vehicles.

- Incorporate adaptive traffic policies: The sensitivity of extreme speeds to traffic volume post-2020 underscores the importance of adaptive measures. Dynamic speed limits that adjust based on real-time traffic and weather conditions could help balance safety and mobility.

- Explore complementary data sources: Expanding beyond radar-collected data to include GPS-based datasets, time-of-day analyses, and seasonal effects could provide richer insights. Doing so would allow for a deeper understanding of the factors driving variability in traffic behavior.

These recommendations highlight the broader applicability of the study’s findings to urban centers experiencing rapid population growth and evolving mobility challenges. By addressing the identified gaps and leveraging the insights gained, Toronto and similar cities can move toward safer and more efficient transportation systems.

\newpage

\appendix

# Appendix {-}

# Data Observation {#sec-dataobservation}

## Idealized Methodology for Traffic Data Collection
The observational data analyzed in this study stems from the City of Toronto’s Safety Zone Watch Your Speed Program (WYSP), where radar-equipped speed signs monitor and aggregate vehicle speeds. While this data provides valuable insights, it also introduces limitations such as restricted spatial and temporal coverage, potential behavioral biases due to the visibility of speed signs, and an inability to capture all traffic volume accurately. This section proposes an idealized methodology to address these limitations and enhance the robustness of traffic speed data collection.

### Goals of the Idealized Methodology

The idealized methodology aims to:

- Expand Representativeness: Ensure the data reflects traffic patterns across different locations, road types, and times of the day.
- Minimize Behavioral Biases: Reduce the influence of drivers’ behavior changes caused by the visibility of monitoring devices.
- Capture Temporal Variability: Account for daily, seasonal, and situational fluctuations in traffic patterns.
- Improve Accuracy: Ensure that all traffic, including vehicles that might evade radar detection, is measured consistently.

### Proposed Framework
- Stratified Sampling Approach
  - To improve spatial representativeness, Toronto can be divided into strata based on geographic regions (e.g., downtown, suburban, and rural areas) and road types (e.g., highways, arterial roads, local streets). The number of monitoring devices deployed in each stratum should be proportional to traffic density and road importance. This stratified approach ensures adequate representation of all areas and road conditions.

- Rotational Monitoring
  - Rather than using permanent installations, monitoring devices should be deployed on a rotational basis. Devices can be moved periodically across selected sites within each stratum, ensuring broader spatial coverage. Rotation would also reduce drivers' habituation to the presence of speed signs, which might otherwise alter their driving behavior.

- Integration of Covert Monitoring
  - To minimize behavioral biases, the methodology should integrate covert monitoring techniques. Hidden radar devices or automated cameras can measure vehicle speeds without drivers being aware of their presence, thus capturing more natural driving behavior.

- Temporal Sampling
  - Data collection should account for temporal variability by monitoring during different times of day (e.g., peak vs. off-peak hours), days of the week (e.g., weekdays vs. weekends), and seasons. This approach ensures a comprehensive understanding of traffic patterns and their fluctuations.

- Technological Enhancements
  - Advanced technologies such as LiDAR and AI-based sensors can supplement traditional radar devices to increase measurement accuracy. These technologies can detect multiple vehicles simultaneously, reducing blind spots and capturing speeds across a wider field of view.

- Calibration and Standardization
  - All monitoring devices must undergo regular calibration to maintain consistency and accuracy in speed measurements. A centralized standardization protocol should be implemented to ensure uniformity across all collected data.

### Challenges and Practical Considerations
Implementing this idealized methodology involves logistical and financial challenges:

- Cost Implications: Deploying advanced devices and rotational monitoring systems requires significant investment in equipment and personnel.
- Coordination with Stakeholders: Accessing certain road segments for device installation may require coordination with local authorities, businesses, and residents.
- Data Management: Large-scale data collection introduces challenges related to storage, integration, and processing. Ensuring data integrity and consistency is critical for effective analysis.

Despite these challenges, the proposed framework offers a robust and realistic solution for improving traffic data collection. By addressing the limitations of the existing WYSP dataset, this methodology provides a foundation for more accurate and actionable insights into urban mobility.

## Simulation for Evaluating the Proposed Framework
Simulations can be an effective way to evaluate the proposed methodology before large-scale implementation. A simulation study could:

- Model Traffic Flow: Use agent-based modeling to simulate traffic flow across Toronto, incorporating variables such as road type, time of day, and vehicle characteristics.
- Test Monitoring Scenarios: Evaluate the effectiveness of rotational and covert monitoring setups in capturing accurate speed data across different strata.
Assess Behavioral Impact: Simulate changes in driver behavior due to visible and hidden monitoring devices to quantify potential biases.
- Optimize Resource Allocation: Simulate various deployment strategies to determine the optimal allocation of monitoring devices for maximum coverage and cost efficiency.

By simulating these scenarios, stakeholders can refine the methodology and address potential challenges before field deployment.

## Strengths and Limitations of Observational Data
The WYSP dataset offers valuable observational insights into Toronto’s traffic patterns, but it is not without its limitations.

### Strengths
- Ease of Collection: Radar speed signs provide a non-intrusive method for collecting large amounts of data over extended periods.
- Focus on Safety Zones: Data collection in designated Safety Zones highlights areas with specific traffic and safety concerns.
- Detailed Metrics: The dataset includes percentile-based speed metrics (e.g., 5th, 50th, and 95th percentiles), which are critical for analyzing traffic behavior.

### Limitations
- Limited Spatial Coverage: The dataset only includes areas with installed speed signs, omitting many road segments across Toronto.
- Behavioral Biases: Visible speed signs may influence drivers to temporarily reduce their speed, resulting in data that may not reflect typical behavior.
- Temporal Gaps: Data is aggregated monthly, obscuring finer temporal variations such as hourly or daily patterns.
- Non-Representative Traffic Volume: The count of vehicles measured by speed signs is not equivalent to total traffic volume, as some vehicles may evade detection.



# Model details {#sec-model-details}

## Posterior predictive check

The posterior predictive check (PPC) evaluates how well the Bayesian model fits the observed data [@tellingstories]. In @fig-ppcheck, the black line represents the observed data density, while the blue lines represent the density of replicated data generated from the posterior predictive distribution. The alignment between these lines indicates the model's ability to reproduce the data. While there is a slight deviation at the peak of the density curve, the overall alignment suggests that the model provides a reasonable fit to the observed data. Minor discrepancies may warrant adjustments in the model specification or inclusion of additional predictors to improve fit.

```{r}
#| label: fig-ppcheck
#| fig-cap: "Examining how the model fits the data through a posterior predictive check"
#| echo: false
#| fig-pos: H
#| message: false
#| warning: false

pp_check(mean_speed_model) +
  theme_classic() +
  theme(legend.position = "bottom")

```

## Comparison of the Posterior and Prior
@fig-postprior compares the prior and posterior distributions for the model parameters. The posterior (left) is informed by the observed data, while the prior (right) reflects initial assumptions [@tellingstories]. Notably, the posterior for all parameters, except the intercept and sigma, remains centered around zero, showing minimal change from the prior. The sigma parameter has shifted slightly to the right, reflecting a more informed estimate based on the data. The red intercept dot spans the entire horizontal range in the prior, indicating a vague prior assumption. This comparison illustrates that the data provides substantial information for refining parameter estimates.

```{r}
#| label: fig-postprior
#| fig-cap: "Comparison of posterior and prior distributions for model parameters"
#| echo: false
#| warning: false
#| fig-pos: H
#| message: false

posterior_vs_prior(mean_speed_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()

```

## Markov Chain Monte Carlo Convergence

### Trace Plot
The trace plot in @fig-trace examines the behavior of the MCMC chains for each parameter [@tellingstories]. The chains exhibit stable horizontal fluctuations with no discernible trends, indicating proper mixing and convergence. The patterns across all six parameters are consistent, suggesting that the algorithm has adequately explored the parameter space.
```{r}
#| label: fig-trace
#| fig-cap: "Trace plot for MCMC convergence assessment"
#| echo: false
#| message: false
#| warning: false
#| fig-pos: H

plot(mean_speed_model, "trace")

```


### Rhat Plot
The Rhat plot in @fig-rhat evaluates the convergence of the Markov Chain Monte Carlo (MCMC) algorithm. The Rhat values for all parameters hover just above 1.00, indicating acceptable convergence. While `pct_05` displays the longest interval, it still falls within the acceptable range. This diagnostic suggests that the chains for all parameters have reached convergence and that the posterior samples are reliable.

```{r}
#| label: fig-rhat
#| fig-cap: "Rhat plot for MCMC convergence assessment"
#| echo: false
#| message: false
#| warning: false
#| fig-pos: H

plot(mean_speed_model, "rhat") +
  theme_classic()

```

## Credible Intervals
The credible intervals for the model coefficients are shown in @fig-credible-intervals. The intercept is negative, suggesting a downward adjustment for baseline mean speed. The `volume` coefficient is centered at 0, indicating little influence on the predicted mean speed. Among the predictors, `pct_50` has the strongest positive effect, with a credible interval between 0.5 and 1.0, while `pct_05` and `pct_95` show moderate positive effects. The residual standard deviation (`sigma`) is near 1.0, reflecting the model's uncertainty in capturing variability.
```{r}
#| label: fig-credible-intervals
#| fig-cap: "95% Credible Intervals for Model Coefficients"
#| echo: false
#| warning: false
#| message: false
#| fig-pos: H

plot(mean_speed_model) +
  theme_classic()
```



\newpage


# References


